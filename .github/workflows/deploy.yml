---
name: Deploy-All

on:
  push:
    branches: ['*_']
    tags:
    - '*_'  # ending underscore for trying things
    - 'v[0-9]+.[0-9]+.[0-9]+'  # final version
    - 'v[0-9]+.[0-9]+.[0-9]+[abrc]+[0-9]+'  # alpha, beta, release candidate (rc)
    - 'v[0-9]+.[0-9]+.[0-9]+.dev[0-9]+'  # development versions

# necessary for Windows
defaults:
  run:
    shell: bash

env:
  WIN_PYTHON_VERSION: 3.10.7
  WIN_LIBRSYNC_VERSION: v2.3.2

jobs:

  build-manylinux:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        # we could do it also as matrix but it takes longer
        #python-version: [3.10,3.9,3.8,3.7]
        #--- Build and deploy Linux wheels using manylinux containers ---
        # - build manylinux2010 x64 and i686
        # - build manylinux2014 x64
        # - build manylinux_2_28 x64
        # avoiding manylinux2014_i686 because does not provide librsync-devel
        # manylinux_2_24 is already deprecated
        many-linux: [2010_x86_64, 2010_i686, 2014_x86_64, _2_28_x86_64]
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # to have the correct version
    - name: create manylinux wheel(s) in a container
      uses: addnab/docker-run-action@v1
      with:
        image: quay.io/pypa/manylinux${{ matrix.many-linux }}
        options: -v ${{ github.workspace }}:/ws
        run: |
          if [[ ${{ matrix.many-linux }} != *64 ]]; then PRE_CMD=linux32; fi
          #py=$(echo ${{ matrix.python-version }} | tr -d .)
          plat=manylinux${{ matrix.many-linux }}
          $PRE_CMD /ws/tools/build_wheels.sh /ws ${plat} /opt/python/cp3{10,9,8,7}*/bin
    - name: Upload wheel artifacts
      uses: actions/upload-artifact@v3
      with:
        name: package-artifacts
        path: dist/*.whl
        if-no-files-found: error

  build-sdist:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # to have the correct version
    - name: Install asciidoctor to generate manpages
      run: |
        sudo apt-get --assume-yes update
        sudo apt-get --assume-yes install asciidoctor
    - name: create source dist package
      run: python setup.py sdist
    - name: Upload sdist artifact
      uses: actions/upload-artifact@v3
      with:
        name: package-artifacts
        path: dist/*.tar.gz
        if-no-files-found: error

  build-windows:
    runs-on: windows-latest
    strategy:
      matrix:
        arch: [x86, x64]
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # to have the correct version
    - name: Set up Python ${{ env.WIN_PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.WIN_PYTHON_VERSION }}
        architecture: ${{ matrix.arch }}
    - name: Install dependencies
      run: tools/win_provision.sh asciidoc
    - name: Build librsync
      run: tools/win_build_librsync.sh ${{ matrix.arch }} ${WIN_LIBRSYNC_VERSION}
    - name: Build rdiff-backup
      run: tools/win_build_rdiffbackup.sh ${{ matrix.arch }} ${WIN_PYTHON_VERSION}
    - name: Package rdiff-backup
      run: tools/win_package_rdiffbackup.sh ${{ matrix.arch }}
    - name: Upload artifacts
      uses: actions/upload-artifact@v3
      with:
        name: package-artifacts
        path: |
          dist/*.zip
          dist/*.whl
        if-no-files-found: error

  test-built-windows:
    runs-on: windows-latest
    needs: [build-windows]
    strategy:
      matrix:
        arch: [x86, x64]
    steps:
    - name: Download artifacts
      id: download
      uses: actions/download-artifact@v2
      with:
        name: package-artifacts
        path: .
    - name: Extract and test Windows binary
      run: |
        ls -la
        if [[ ${{ matrix.arch }} == *64 ]]; then bits=64; else bits=32; fi 
        7z x rdiff-backup-*.win${bits}exe.zip
        cd rdiff-backup-*-${bits}
        pwd
        ls -la
        ./rdiff-backup.exe --help
        ./rdiff-backup.exe info
        ./rdiff-backup.exe -v5 backup . ../bak${bits}
        ./rdiff-backup.exe -v5 verify ../bak${bits}
        ./rdiff-backup.exe -v5 restore ../bak${bits} to
        ls -la to/

  release:
    runs-on: ubuntu-latest
    needs: [build-manylinux, build-sdist, test-built-windows]
    steps:
    - name: Download artifacts
      id: download
      uses: actions/download-artifact@v2
      with:
        name: package-artifacts
        path: dist
    - name: Export artifacts
      id: export
      run: echo artifact_files=${{ steps.download.outputs.download-path }}/*.* >> $GITHUB_OUTPUT
      # see https://jasonet.co/posts/new-features-of-github-actions/#passing-data-to-future-steps
    - name: Create release and upload assets to GitHub
      uses: meeDamian/github-release@2.0
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        tag: ${{ github.ref }}
        name: Release ${{ github.ref }} ${{ github.event_name }}
        draft: true
        prerelease: true
        files: ${{ steps.export.outputs.artifact_files }}
        gzip: false
    - name: Install twine
      if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v')
      run: |
        sudo python -m pip install --upgrade pip
        sudo pip install twine
    - name: publish to test PyPI repository
      if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v') && contains(github.ref, '.dev')
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN_TEST }}
        TWINE_REPOSITORY_URL: https://test.pypi.org/legacy/ 
      run: |
        twine upload --skip-existing --verbose dist/rdiff*.{whl,tar.gz}
        # old versions don't understand --non-interactive
    - name: publish to PyPI repository
      if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v') && ! contains(github.ref, '.dev')
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}
      run: |
        twine upload --skip-existing --verbose dist/rdiff*.{whl,tar.gz}
        # old versions don't understand --non-interactive

#    #--- Build Debian packages ---
#    - os: linux
#      language: shell
#      env: MAKE_STEP=dist_deb RUN_COMMAND=
#      addons:
#        apt:
#          packages:  # make sure these match debian/control contents
#            - build-essential
#            - debhelper-compat
#            - dh-python
#            - fakeroot
#            - git-buildpackage
#            - librsync-dev
#            - python3-all-dev
#            - python3-pylibacl
#            - python3-pyxattr
#            - python3-setuptools
#            - python3-setuptools-scm
#      install:
#        - echo "No pip here"
#      script:
#        - make $MAKE_STEP
#        - cat ../*.changes
